{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team Name:** DataNerds\n",
    "\n",
    "**Student Details:**\n",
    "\n",
    "--------------------------\n",
    "\n",
    "Name : Reshma Vijay Jawale\n",
    "\n",
    "Student Id : A0236581B\n",
    "\n",
    "--------------------------\n",
    "Name : Aiden Low Yew Woei\n",
    "\n",
    "Student Id : A0121969W\n",
    "\n",
    "--------------------------\n",
    "Name : Raivat Bhupesh Shah \n",
    "\n",
    "Student Id : A0184879A\n",
    "\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cleaning methods\n",
    "import library_code.cleaning as cleaning\n",
    "import library_code.constants as constants\n",
    "import library_code.imputation as imputation\n",
    "import library_code.auxiliary as auxiliary\n",
    "\n",
    "# Scikit learn\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# For adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_prices_test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "The data cleaning steps here are based off our EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, drop all fields in TO_IGNORE as these columns are either redundant\n",
    "# e.g. we drop model because we have type\n",
    "# or they only have one unique value, e.g. 'market_segment' and 'type_of_area'.\n",
    "df_prices_train = df_prices_train.drop(columns=constants.TO_IGNORE)\n",
    "df_prices_test = df_prices_test.drop(columns=constants.TO_IGNORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we clean up the tenure fields to 3 categories: 60 years, 99 years, and freehold/999\n",
    "df_prices_train['tenure'] = df_prices_train['tenure'].apply(cleaning.tenure_to_binary)\n",
    "df_prices_test['tenure'] = df_prices_test['tenure'].apply(cleaning.tenure_to_binary)\n",
    "# Perform one hot encoding\n",
    "df_prices_train = cleaning.categorical_to_onehot(df_prices_train, ['tenure', 'type', 'region', 'planning_area'])\n",
    "df_prices_test = cleaning.categorical_to_onehot(df_prices_test, ['tenure', 'type', 'region', 'planning_area'])\n",
    "# Remove 'planning_area_seletar' column in test as that's not seen in train.\n",
    "df_prices_test.drop(columns=['planning_area_seletar'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning values for bedroom and bathroom\n",
    "\n",
    "Some of the values in the bedroom column are math expressions, e.g. '4+1. We're not sure what this means! Is it 5 bedrooms? Is the +1 because it is not a *full room* (e.g. a servant quarter or living room) or is the +1 referring to a bathroom? Due to these different possibilities, we follow an iterative approach where for we take 4+1 as 5, 4.5 (to quantify only half a room) and 4 (to quantify no room). We will go with the representation that gives us the most accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>district</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>no_of_units</th>\n",
       "      <th>area_size</th>\n",
       "      <th>price</th>\n",
       "      <th>tenure_60</th>\n",
       "      <th>tenure_99</th>\n",
       "      <th>...</th>\n",
       "      <th>planning_area_sembawang</th>\n",
       "      <th>planning_area_sengkang</th>\n",
       "      <th>planning_area_serangoon</th>\n",
       "      <th>planning_area_singapore river</th>\n",
       "      <th>planning_area_southern islands</th>\n",
       "      <th>planning_area_tampines</th>\n",
       "      <th>planning_area_tanglin</th>\n",
       "      <th>planning_area_toa payoh</th>\n",
       "      <th>planning_area_woodlands</th>\n",
       "      <th>planning_area_yishun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.314620</td>\n",
       "      <td>103.932237</td>\n",
       "      <td>116.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>715000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1.292988</td>\n",
       "      <td>103.851047</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6609.0</td>\n",
       "      <td>27423000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.274644</td>\n",
       "      <td>103.844742</td>\n",
       "      <td>360.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>990000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.274644</td>\n",
       "      <td>103.844742</td>\n",
       "      <td>360.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>1.335557</td>\n",
       "      <td>103.742417</td>\n",
       "      <td>738.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>1045000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25849</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.376176</td>\n",
       "      <td>103.960488</td>\n",
       "      <td>473.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>693000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25866</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1.379727</td>\n",
       "      <td>103.760191</td>\n",
       "      <td>338.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>825000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25884</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.277083</td>\n",
       "      <td>103.849181</td>\n",
       "      <td>510.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1099800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25916</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.297510</td>\n",
       "      <td>103.856297</td>\n",
       "      <td>522.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>1098900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.311510</td>\n",
       "      <td>103.858718</td>\n",
       "      <td>28.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>858000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  bathrooms  district       lat         lng  no_of_units  \\\n",
       "59          NaN        1.0        15  1.314620  103.932237        116.0   \n",
       "111         NaN        NaN         6  1.292988  103.851047         39.0   \n",
       "203         NaN        1.0         2  1.274644  103.844742        360.0   \n",
       "296         NaN        1.0         2  1.274644  103.844742        360.0   \n",
       "443         NaN        NaN        22  1.335557  103.742417        738.0   \n",
       "...         ...        ...       ...       ...         ...          ...   \n",
       "25849       NaN        1.0        18  1.376176  103.960488        473.0   \n",
       "25866       NaN        2.0        23  1.379727  103.760191        338.0   \n",
       "25884       NaN        1.0         1  1.277083  103.849181        510.0   \n",
       "25916       NaN        1.0         7  1.297510  103.856297        522.0   \n",
       "26000       NaN        1.0         8  1.311510  103.858718         28.0   \n",
       "\n",
       "       area_size       price  tenure_60  tenure_99  ...  \\\n",
       "59         409.0    715000.0          0          0  ...   \n",
       "111       6609.0  27423000.0          0          1  ...   \n",
       "203        365.0    990000.0          0          1  ...   \n",
       "296        365.0   1100000.0          0          1  ...   \n",
       "443        506.0   1045000.0          0          1  ...   \n",
       "...          ...         ...        ...        ...  ...   \n",
       "25849      571.0    693000.0          0          1  ...   \n",
       "25866      624.0    825000.0          0          1  ...   \n",
       "25884      441.0   1099800.0          0          1  ...   \n",
       "25916      409.0   1098900.0          0          1  ...   \n",
       "26000      441.0    858000.0          0          0  ...   \n",
       "\n",
       "       planning_area_sembawang  planning_area_sengkang  \\\n",
       "59                           0                       0   \n",
       "111                          0                       0   \n",
       "203                          0                       0   \n",
       "296                          0                       0   \n",
       "443                          0                       0   \n",
       "...                        ...                     ...   \n",
       "25849                        0                       0   \n",
       "25866                        0                       0   \n",
       "25884                        0                       0   \n",
       "25916                        0                       0   \n",
       "26000                        0                       0   \n",
       "\n",
       "       planning_area_serangoon  planning_area_singapore river  \\\n",
       "59                           0                              0   \n",
       "111                          0                              0   \n",
       "203                          0                              0   \n",
       "296                          0                              0   \n",
       "443                          0                              0   \n",
       "...                        ...                            ...   \n",
       "25849                        0                              0   \n",
       "25866                        0                              0   \n",
       "25884                        0                              0   \n",
       "25916                        0                              0   \n",
       "26000                        0                              0   \n",
       "\n",
       "       planning_area_southern islands  planning_area_tampines  \\\n",
       "59                                  0                       0   \n",
       "111                                 0                       0   \n",
       "203                                 0                       0   \n",
       "296                                 0                       0   \n",
       "443                                 0                       0   \n",
       "...                               ...                     ...   \n",
       "25849                               0                       0   \n",
       "25866                               0                       0   \n",
       "25884                               0                       0   \n",
       "25916                               0                       0   \n",
       "26000                               0                       0   \n",
       "\n",
       "       planning_area_tanglin  planning_area_toa payoh  \\\n",
       "59                         0                        0   \n",
       "111                        0                        0   \n",
       "203                        0                        0   \n",
       "296                        0                        0   \n",
       "443                        0                        0   \n",
       "...                      ...                      ...   \n",
       "25849                      0                        0   \n",
       "25866                      0                        0   \n",
       "25884                      0                        0   \n",
       "25916                      0                        0   \n",
       "26000                      0                        0   \n",
       "\n",
       "       planning_area_woodlands  planning_area_yishun  \n",
       "59                           0                     0  \n",
       "111                          0                     0  \n",
       "203                          0                     0  \n",
       "296                          0                     0  \n",
       "443                          0                     0  \n",
       "...                        ...                   ...  \n",
       "25849                        0                     0  \n",
       "25866                        0                     0  \n",
       "25884                        0                     0  \n",
       "25916                        0                     0  \n",
       "26000                        0                     0  \n",
       "\n",
       "[404 rows x 56 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices_train['bedrooms'] = df_prices_train['bedrooms'].apply(cleaning.process_bedroom_sum)\n",
    "df_prices_test['bedrooms'] = df_prices_test['bedrooms'].apply(cleaning.process_bedroom_sum)\n",
    "df_prices_train[df_prices_train['bedrooms'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 107\n",
      "max_resources_: 26048\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 500\n",
      "n_resources: 107\n",
      "Fitting 10 folds for each of 500 candidates, totalling 5000 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 167\n",
      "n_resources: 321\n",
      "Fitting 10 folds for each of 167 candidates, totalling 1670 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 56\n",
      "n_resources: 963\n",
      "Fitting 10 folds for each of 56 candidates, totalling 560 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 19\n",
      "n_resources: 2889\n",
      "Fitting 10 folds for each of 19 candidates, totalling 190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs5228/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 4\n",
      "n_candidates: 7\n",
      "n_resources: 8667\n",
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    }
   ],
   "source": [
    "X_train = df_prices_train.loc[:, df_prices_train.columns != 'price']\n",
    "y_train = df_prices_train['price'].values.ravel()\n",
    "\n",
    "model = AdaBoostRegressor(base_estimator=DecisionTreeRegressor())\n",
    "# Set up pipeline with imputer for proper grid search\n",
    "# Reference: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "pipeline = Pipeline(steps=[('scaler', MinMaxScaler()), ('imputer', KNNImputer()), ('model', model)])\n",
    "\n",
    "# define grid search for hyperparameters\n",
    "grid = {\n",
    "    'imputer__n_neighbors': [3, 5, 7, 11, 15],\n",
    "    'model__base_estimator__max_depth': [i for i in range(1, 21, 2)],\n",
    "    'model__n_estimators': [50, 100, 150, 250, 500],\n",
    "    'model__learning_rate': [0.1, 1.0],\n",
    "}\n",
    "# Repeats set at 3 to reduce model \n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "grid_search = HalvingGridSearchCV(estimator=pipeline, param_grid=grid, cv=cv, n_jobs=-1, scoring=mse, verbose=1)\n",
    "# Execute the grid search\n",
    "grid_results = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 1002524.512938 using {'imputer__n_neighbors': 3, 'model__base_estimator__max_depth': 13, 'model__learning_rate': 1.0, 'model__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Get RMSE of grid results best score\n",
    "best_rmse = (-grid_results.best_score_) ** 0.5\n",
    "print(\"Best: %f using %s\" % (best_rmse, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = grid_results\n",
    "X_test = df_prices_test[:]\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Predicted\": y_pred})\n",
    "result.index.name = \"Id\"\n",
    "result.to_csv(\"submission_adaboost.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "X_train = df_prices_train.loc[:, df_prices_train.columns != 'price']\n",
    "y_train = df_prices_train[['price']].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26048, 55)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 107\n",
      "max_resources_: 26048\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 600\n",
      "n_resources: 107\n",
      "Fitting 10 folds for each of 600 candidates, totalling 6000 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 200\n",
      "n_resources: 321\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 67\n",
      "n_resources: 963\n",
      "Fitting 10 folds for each of 67 candidates, totalling 670 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 23\n",
      "n_resources: 2889\n",
      "Fitting 10 folds for each of 23 candidates, totalling 230 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs5228/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 4\n",
      "n_candidates: 8\n",
      "n_resources: 8667\n",
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_jobs=-1)\n",
    "# Set up pipeline with imputer for proper grid search\n",
    "# Reference: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "pipeline = Pipeline(steps=[('scaler', MinMaxScaler()), ('imputer', KNNImputer()), ('model', model)])\n",
    "\n",
    "# define grid search for hyperparameters\n",
    "grid = {\n",
    "    'imputer__n_neighbors': [3, 5, 7, 11, 15],\n",
    "    'model__max_features': ['auto', 'sqrt'],\n",
    "    'model__max_depth': [i for i in range(1, 21, 2)],\n",
    "    'model__n_estimators': [25, 50, 100, 150, 250, 500],\n",
    "}\n",
    "\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "# define grid search for hyperparameters\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "grid_search = HalvingGridSearchCV(estimator=pipeline, param_grid=grid, n_jobs=-1, cv=cv, scoring=mse, verbose=1)\n",
    "# Execute the grid search\n",
    "grid_results = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 1159476.955259 using {'imputer__n_neighbors': 3, 'model__max_depth': 17, 'model__max_features': 'auto', 'model__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Get RMSE of grid results best score\n",
    "best_rmse = (-grid_results.best_score_) ** 0.5\n",
    "print(\"Best: %f using %s\" % (best_rmse, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid_results\n",
    "X_test = df_prices_test.loc[:, df_prices_test.columns != 'price']\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Predicted\": y_pred})\n",
    "result.index.name = \"Id\"\n",
    "result.to_csv(\"submission_forest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 55)\n",
      "n_iterations: 7\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 7\n",
      "min_resources_: 35\n",
      "max_resources_: 26048\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1000\n",
      "n_resources: 35\n",
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 334\n",
      "n_resources: 105\n",
      "Fitting 10 folds for each of 334 candidates, totalling 3340 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 112\n",
      "n_resources: 315\n",
      "Fitting 10 folds for each of 112 candidates, totalling 1120 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 38\n",
      "n_resources: 945\n",
      "Fitting 10 folds for each of 38 candidates, totalling 380 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 13\n",
      "n_resources: 2835\n",
      "Fitting 10 folds for each of 13 candidates, totalling 130 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 5\n",
      "n_resources: 8505\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs5228/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 6\n",
      "n_candidates: 2\n",
      "n_resources: 25515\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "X_train = df_prices_train.loc[:, df_prices_train.columns != 'price']\n",
    "y_train = df_prices_train[['price']].values.ravel()\n",
    "print(X_train.shape)\n",
    "model = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_jobs=-1)\n",
    "# Set up pipeline with imputer for proper grid search\n",
    "# Reference: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "pipeline = Pipeline(steps=[('scaler', MinMaxScaler()), ('imputer', KNNImputer()), ('model', model)])\n",
    "\n",
    "# define grid search for hyperparameters\n",
    "grid = {\n",
    "    'imputer__n_neighbors': [3, 5, 7, 11, 15],\n",
    "    'model__max_features': [0.5, 0.7, 0.9, 1],\n",
    "    'model__base_estimator__max_depth': [i for i in range(1, 21, 2)],\n",
    "    'model__n_estimators': [50, 100, 150, 250, 500],\n",
    "}\n",
    "\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "# define grid search for hyperparameters\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "grid_search = HalvingGridSearchCV(estimator=pipeline, param_grid=grid, n_jobs=-1, cv=cv, scoring=mse, verbose=1)\n",
    "# Execute the grid search\n",
    "grid_results = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 796625.230065 using {'imputer__n_neighbors': 3, 'model__base_estimator__max_depth': 17, 'model__max_features': 0.9, 'model__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Get RMSE of grid results best score\n",
    "best_rmse = (-grid_results.best_score_) ** 0.5\n",
    "print(\"Best: %f using %s\" % (best_rmse, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "clf = grid_results\n",
    "X_test = df_prices_test.loc[:, df_prices_test.columns != 'price']\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Predicted\": y_pred})\n",
    "result.index.name = \"Id\"\n",
    "result.to_csv(\"submission_bagging.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 55)\n",
      "n_iterations: 7\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 7\n",
      "min_resources_: 35\n",
      "max_resources_: 26048\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2000\n",
      "n_resources: 35\n",
      "Fitting 10 folds for each of 2000 candidates, totalling 20000 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 667\n",
      "n_resources: 105\n",
      "Fitting 10 folds for each of 667 candidates, totalling 6670 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 223\n",
      "n_resources: 315\n",
      "Fitting 10 folds for each of 223 candidates, totalling 2230 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 75\n",
      "n_resources: 945\n",
      "Fitting 10 folds for each of 75 candidates, totalling 750 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 25\n",
      "n_resources: 2835\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 9\n",
      "n_resources: 8505\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 3\n",
      "n_resources: 25515\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs5228/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "X_train = df_prices_train.loc[:, df_prices_train.columns != 'price']\n",
    "y_train = df_prices_train[['price']].values.ravel()\n",
    "print(X_train.shape)\n",
    "model = GradientBoostingRegressor()\n",
    "# Set up pipeline with imputer for proper grid search\n",
    "# Reference: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "pipeline = Pipeline(steps=[('scaler', MinMaxScaler()), ('imputer', KNNImputer()), ('model', model)])\n",
    "\n",
    "# define grid search for hyperparameters\n",
    "grid = {\n",
    "    'imputer__n_neighbors': [3, 5, 7, 11, 15],\n",
    "    'model__subsample': [0.2, 0.5, 0.9, 1],\n",
    "    'model__max_features': ['auto', 'sqrt'],\n",
    "    'model__max_depth': [i for i in range(1, 21, 2)],\n",
    "    'model__n_estimators': [50, 100, 150, 250, 500],\n",
    "}\n",
    "\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "# define grid search for hyperparameters\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "grid_search = HalvingGridSearchCV(estimator=pipeline, param_grid=grid, n_jobs=-1, cv=cv, scoring=mse, verbose=1)\n",
    "# Execute the grid search\n",
    "grid_results = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 759509.398026 using {'imputer__n_neighbors': 5, 'model__max_depth': 7, 'model__max_features': 'auto', 'model__n_estimators': 500, 'model__subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Get RMSE of grid results best score\n",
    "best_rmse = (-grid_results.best_score_) ** 0.5\n",
    "print(\"Best: %f using %s\" % (best_rmse, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "clf = grid_results\n",
    "X_test = df_prices_test.loc[:, df_prices_test.columns != 'price']\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Predicted\": y_pred})\n",
    "result.index.name = \"Id\"\n",
    "result.to_csv(\"submission_gradient_boosting_no_aux_add_inflation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 55)\n",
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 2894\n",
      "max_resources_: 26048\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 10\n",
      "n_resources: 2894\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 4\n",
      "n_resources: 8682\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs5228/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 2\n",
      "n_candidates: 2\n",
      "n_resources: 26046\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "X_train = df_prices_train.loc[:, df_prices_train.columns != 'price']\n",
    "y_train = df_prices_train[['price']].values.ravel()\n",
    "print(X_train.shape)\n",
    "model = LinearRegression()\n",
    "# Set up pipeline with imputer for proper grid search\n",
    "# Reference: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "pipeline = Pipeline(steps=[('scaler', MinMaxScaler()), ('imputer', KNNImputer()), ('model', model)])\n",
    "\n",
    "# define grid search for hyperparameters\n",
    "grid = {\n",
    "    'imputer__n_neighbors': [3, 5, 7, 11, 15],\n",
    "    'model__fit_intercept': [False, True],\n",
    "}\n",
    "\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "# define grid search for hyperparameters\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "grid_search = HalvingGridSearchCV(estimator=pipeline, param_grid=grid, n_jobs=-1, cv=cv, scoring=mse, verbose=1)\n",
    "# Execute the grid search\n",
    "grid_results = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 1912274.814626 using {'imputer__n_neighbors': 15, 'model__fit_intercept': False}\n"
     ]
    }
   ],
   "source": [
    "# Get RMSE of grid results best score\n",
    "best_rmse = (-grid_results.best_score_) ** 0.5\n",
    "print(\"Best: %f using %s\" % (best_rmse, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "clf = grid_results\n",
    "X_test = df_prices_test.loc[:, df_prices_test.columns != 'price']\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Predicted\": y_pred})\n",
    "result.index.name = \"Id\"\n",
    "result.to_csv(\"submission_linear_regression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 55)\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 8682\n",
      "max_resources_: 26048\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 5\n",
      "n_resources: 8682\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 2\n",
      "n_resources: 26046\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cs5228/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "X_train = df_prices_train.loc[:, df_prices_train.columns != 'price']\n",
    "y_train = df_prices_train[['price']].values.ravel()\n",
    "print(X_train.shape)\n",
    "model = BayesianRidge()\n",
    "# Set up pipeline with imputer for proper grid search\n",
    "# Reference: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "pipeline = Pipeline(steps=[('scaler', MinMaxScaler()), ('imputer', KNNImputer()), ('model', model)])\n",
    "\n",
    "# define grid search for hyperparameters\n",
    "grid = {\n",
    "    'imputer__n_neighbors': [3, 5, 7, 11, 15],\n",
    "}\n",
    "\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "# define grid search for hyperparameters\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "grid_search = HalvingGridSearchCV(estimator=pipeline, param_grid=grid, n_jobs=-1, cv=cv, scoring=mse, verbose=1)\n",
    "# Execute the grid search\n",
    "grid_results = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 1912495.609717 using {'imputer__n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "# Get RMSE of grid results best score\n",
    "best_rmse = (-grid_results.best_score_) ** 0.5\n",
    "print(\"Best: %f using %s\" % (best_rmse, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "clf = grid_results\n",
    "X_test = df_prices_test.loc[:, df_prices_test.columns != 'price']\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Predicted\": y_pred})\n",
    "result.index.name = \"Id\"\n",
    "result.to_csv(\"submission_bayesian_regression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 55)\n",
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 964\n",
      "max_resources_: 26048\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 80\n",
      "n_resources: 964\n",
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 27\n",
      "n_resources: 2892\n",
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 9\n",
      "n_resources: 8676\n",
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 26028\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "X_train = df_prices_train.loc[:, df_prices_train.columns != 'price']\n",
    "y_train = df_prices_train[['price']].values.ravel()\n",
    "print(X_train.shape)\n",
    "model = KNeighborsRegressor()\n",
    "# Set up pipeline with imputer for proper grid search\n",
    "# Reference: https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "pipeline = Pipeline(steps=[('scaler', MinMaxScaler()), ('imputer', KNNImputer()), ('model', model)])\n",
    "\n",
    "# define grid search for hyperparameters\n",
    "grid = {\n",
    "    'imputer__n_neighbors': [3, 5, 7, 11, 15],\n",
    "    'model__n_neighbors': [i for i in range(1, 32, 2)]\n",
    "}\n",
    "\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "# define grid search for hyperparameters\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "grid_search = HalvingGridSearchCV(estimator=pipeline, param_grid=grid, n_jobs=-1, cv=cv, scoring=mse, verbose=1)\n",
    "# Execute the grid search\n",
    "grid_results = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 1033868.471874 using {'imputer__n_neighbors': 11, 'model__n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "# Get RMSE of grid results best score\n",
    "best_rmse = (-grid_results.best_score_) ** 0.5\n",
    "print(\"Best: %f using %s\" % (best_rmse, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "clf = grid_results\n",
    "X_test = df_prices_test.loc[:, df_prices_test.columns != 'price']\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Predicted\": y_pred})\n",
    "result.index.name = \"Id\"\n",
    "result.to_csv(\"submission_kneighbors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
